// This file is part of ICU4X. For terms of use, please see the file
// called LICENSE at the top level of the ICU4X source tree
// (online at: https://github.com/unicode-org/icu4x/blob/main/LICENSE ).

use icu_datagen::baked_exporter::*;
use icu_datagen::blob_exporter::*;
use icu_datagen::fs_exporter::serializers::*;
use icu_datagen::fs_exporter::*;
use icu_datagen::prelude::*;
use icu_provider::datagen::*;
use icu_provider::prelude::*;
use std::collections::BTreeSet;
use std::fs::File;
use std::io::Write;
use std::path::Path;
use std::sync::Mutex;

#[global_allocator]
static ALLOC: dhat::Alloc = dhat::Alloc;

include!("../../locales.rs.data");

fn main() {
    simple_logger::SimpleLogger::new()
        .env()
        .with_level(log::LevelFilter::Info)
        .init()
        .unwrap();

    let data_root = Path::new(concat!(
        core::env!("CARGO_MANIFEST_DIR"),
        "/../../provider/datagen/tests/data/"
    ));

    let testdata_data_root = Path::new(concat!(
        core::env!("CARGO_MANIFEST_DIR"),
        "/../../provider/testdata/data/"
    ));

    let source = SourceData::offline()
        .with_cldr(data_root.join("cldr"), Default::default())
        .unwrap()
        .with_icuexport(data_root.join("icuexport"))
        .unwrap();

    let json_out = Box::new(
        FilesystemExporter::try_new(Box::new(Json::pretty()), {
            let mut options = ExporterOptions::default();
            options.root = data_root.join("json");
            options.overwrite = OverwriteOption::RemoveAndReplace;
            options.fingerprint = true;
            options
        })
        .unwrap(),
    );

    let postcard_out = Box::new(
        FilesystemExporter::try_new(Box::<Postcard>::default(), {
            let mut options = ExporterOptions::default();
            options.root = data_root.join("postcard");
            options.overwrite = OverwriteOption::RemoveAndReplace;
            options.fingerprint = true;
            options
        })
        .unwrap(),
    );

    let blob_out = Box::new(BlobExporter::new_with_sink(Box::new(
        File::create(testdata_data_root.join("testdata.postcard")).unwrap(),
    )));

    let mod_out = Box::new(
        BakedExporter::new(testdata_data_root.join("baked"), {
            let mut options = Options::default();
            options.insert_feature_gates = true;
            options.use_separate_crates = true;
            options.overwrite = true;
            options.pretty = true;
            options
        })
        .unwrap(),
    );

    let zero_copy_test_out = Box::<VerifyZeroCopyExporter>::default();

    let mut options = options::Options::default();
    options.locales = options::LocaleInclude::Explicit(LOCALES.iter().cloned().collect());

    DatagenProvider::try_new(options, source)
        .unwrap()
        .export(
            icu_datagen::all_keys()
                .into_iter()
                .chain([icu_provider::hello_world::HelloWorldV1Marker::KEY])
                .collect(),
            MultiExporter::new(vec![
                json_out,
                blob_out,
                mod_out,
                postcard_out,
                zero_copy_test_out,
            ]),
        )
        .unwrap();

    let mut metadata = File::create(testdata_data_root.join("metadata.rs.data")).unwrap();

    metadata
        .write_all(
            "\
             // DO NOT EDIT\n\
             // This file is generated by `make-testdata` from\n\
             // * tools/testdata-scripts/locales.rs.data,\n\
             // * `icu_datagen::SourceData::LATEST_TESTED_*`.\n\
             \n\
            "
            .as_bytes(),
        )
        .unwrap();

    let locales = databake::Bake::bake(LOCALES, &Default::default());
    let cldr_tag = SourceData::LATEST_TESTED_CLDR_TAG;
    let icu_tag = SourceData::LATEST_TESTED_ICUEXPORT_TAG;
    let lstm_tag = SourceData::LATEST_TESTED_SEGMENTER_LSTM_TAG;

    metadata
        .write_all(
            quote::quote! {
                pub const LOCALES: &[icu_locid::LanguageIdentifier] = &#locales;
                pub const CLDR_TAG: &str = #cldr_tag;
                pub const ICUEXPORT_TAG: &str = #icu_tag;
                pub const SEGMENTER_LSTM_TAG: &str = #lstm_tag;
            }
            .to_string()
            .as_bytes(),
        )
        .unwrap();
}

#[derive(Default)]
struct VerifyZeroCopyExporter {
    payloads: Mutex<Vec<(DataKey, Box<[u8]>)>>,
}

impl DataExporter for VerifyZeroCopyExporter {
    fn put_payload(
        &self,
        key: DataKey,
        _: &DataLocale,
        payload: &DataPayload<ExportMarker>,
    ) -> Result<(), DataError> {
        use ::postcard::{
            ser_flavors::{AllocVec, Flavor},
            Serializer,
        };

        let mut serializer = Serializer {
            output: AllocVec::new(),
        };
        payload.serialize(&mut serializer)?;
        let output = serializer
            .output
            .finalize()
            .expect("Failed to finalize serializer output");

        self.payloads
            .lock()
            .expect("poison")
            .push((key, output.into_boxed_slice()));
        Ok(())
    }

    // Actual deserialization has to be done in `close`, as `put_payload` is called
    // concurrently and we cannot perform reliable heap measurements.
    fn close(&mut self) -> Result<(), DataError> {
        // don't drop to avoid dhat from printing stats at the end
        core::mem::forget(dhat::Profiler::new_heap());

        // violations for net_bytes_allocated
        let mut net_violations = BTreeSet::new();
        // violations for total_bytes_allocated (but not net_bytes_allocated)
        let mut total_violations = BTreeSet::new();

        for (key, payload) in self.payloads.get_mut().expect("poison").drain(..) {
            let payload = DataPayload::from_owned_buffer(payload);

            let stats_before = dhat::HeapStats::get();

            // We need to generate the stats before the deserialized struct gets dropped, in order
            // to distinguish between a temporary and permanent allocation.
            let stats_after =
                icu_datagen::deserialize_and_discard(key, payload, dhat::HeapStats::get).unwrap();

            if stats_after.total_bytes != stats_before.total_bytes {
                if stats_after.curr_bytes != stats_before.curr_bytes {
                    net_violations.insert(key.path().get());
                } else {
                    total_violations.insert(key.path().get());
                }
            }
        }

        // Types in this list cannot be zero-copy deserialized.
        //
        // Such types contain some data that was allocated during deserializations
        //
        // Every entry in this list is a bug that needs to be addressed before ICU4X 1.0.
        const EXPECTED_NET_VIOLATIONS: &[&str] = &[
            // https://github.com/unicode-org/icu4x/issues/1678
            "datetime/skeletons@1",
        ];

        // Types in this list can be zero-copy deserialized (and do not contain allocated data),
        // however there is some allocation that occurs during deserialization for validation.
        //
        // Entries in this list represent a less-than-ideal state of things, however ICU4X is shippable with violations
        // in this list since it does not affect databake.
        const EXPECTED_TOTAL_VIOLATIONS: &[&str] = &[
            // Regex DFAs need to be validated, which involved creating a BTreeMap
            "list/and@1",
            "list/or@1",
            "list/unit@1",
        ];

        assert!(total_violations.iter().eq(EXPECTED_TOTAL_VIOLATIONS.iter()) && net_violations.iter().eq(EXPECTED_NET_VIOLATIONS.iter()),
            "Expected violations list does not match found violations!\n\
            If the new list is smaller, please update EXPECTED_VIOLATIONS in make-testdata.rs\n\
            If it is bigger and that was unexpected, please make sure the key remains zero-copy, or ask ICU4X team members if it is okay\
            to temporarily allow for this key to be allowlisted.\n\
            Expected (net):\n{EXPECTED_NET_VIOLATIONS:?}\nFound (net):\n{net_violations:?}\nExpected (total):\n{EXPECTED_TOTAL_VIOLATIONS:?}\nFound (total):\n{total_violations:?}");
        Ok(())
    }
}
